# è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½

è¿™æ˜¯ä¸€ä¸ªé›†æˆäº†å¤šç§è¯­éŸ³è¯†åˆ«æœåŠ¡çš„è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½æ¨¡å—ï¼Œæ”¯æŒæœ¬åœ°å’Œäº‘ç«¯è¯­éŸ³è¯†åˆ«ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ¯ **å¤šç§æœåŠ¡æ”¯æŒ**: æ”¯æŒ OpenAI Whisper API å’Œæœ¬åœ° Whisper æ¨¡å‹
- ğŸ“ **æ‰¹é‡å¤„ç†**: æ”¯æŒæ‰¹é‡è½¬å½•éŸ³é¢‘æ–‡ä»¶
- ğŸ”„ **éŸ³é¢‘é¢„å¤„ç†**: æ”¯æŒéŸ³é¢‘æ ¼å¼è½¬æ¢å’Œé¢„å¤„ç†
- ğŸŒ **RESTful API**: æä¾›å®Œæ•´çš„ API æ¥å£
- ğŸ›¡ï¸ **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

## å®‰è£…ä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£…éŸ³é¢‘å¤„ç†ç›¸å…³ä¾èµ–
pip install librosa soundfile openai-whisper pyaudio
```

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
from app.core.voice_to_text import VoiceToTextService

# åˆ›å»ºæœåŠ¡å®ä¾‹
service = VoiceToTextService(default_service="whisper")

# è½¬å½•éŸ³é¢‘æ–‡ä»¶
result = service.transcribe_file("audio.wav")
print(f"è½¬å½•ç»“æœ: {result}")
```

### 2. ä½¿ç”¨ OpenAI API

```python
import os
from app.core.voice_to_text import VoiceToTextService

# è®¾ç½® API Key
os.environ["OPENAI_API_KEY"] = "your-api-key"

# åˆ›å»ºæœåŠ¡å®ä¾‹
service = VoiceToTextService(default_service="openai", api_key=os.getenv("OPENAI_API_KEY"))

# è½¬å½•éŸ³é¢‘æ–‡ä»¶
result = service.transcribe_file("audio.wav", service_type="openai")
print(f"è½¬å½•ç»“æœ: {result}")
```

### 3. æ‰¹é‡è½¬å½•

```python
from app.core.voice_to_text import VoiceToTextService

service = VoiceToTextService()

# æ‰¹é‡è½¬å½•
audio_files = ["audio1.wav", "audio2.wav", "audio3.wav"]
results = service.batch_transcribe(audio_files)

for file, result in results.items():
    print(f"{file}: {result}")
```

## API æ¥å£

### 1. å•ä¸ªæ–‡ä»¶è½¬å½•

**POST** `/voice/transcribe`

**å‚æ•°:**
- `file`: éŸ³é¢‘æ–‡ä»¶ (multipart/form-data)
- `service_type`: æœåŠ¡ç±»å‹ (whisper/openai)
- `language`: è¯­è¨€ä»£ç  (zh/en)
- `task`: ä»»åŠ¡ç±»å‹ (transcribe/translate)

**ç¤ºä¾‹:**
```bash
curl -X POST "http://localhost:8000/voice/transcribe" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@audio.wav" \
  -F "service_type=whisper" \
  -F "language=zh"
```

### 2. æ‰¹é‡è½¬å½•

**POST** `/voice/transcribe-batch`

**å‚æ•°:**
- `files`: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨ (multipart/form-data)
- `service_type`: æœåŠ¡ç±»å‹

### 3. è·å–å¯ç”¨æœåŠ¡

**GET** `/voice/services`

### 4. å¥åº·æ£€æŸ¥

**GET** `/voice/health`

## æ”¯æŒçš„æœåŠ¡

### 1. æœ¬åœ° Whisper æ¨¡å‹

- **ä¼˜ç‚¹**: æ— éœ€ç½‘ç»œè¿æ¥ï¼Œéšç§æ€§å¥½
- **ç¼ºç‚¹**: éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œå ç”¨æœ¬åœ°èµ„æº
- **é€‚ç”¨åœºæ™¯**: ç¦»çº¿ç¯å¢ƒï¼Œéšç§è¦æ±‚é«˜çš„åœºæ™¯

```python
service = VoiceToTextService(default_service="whisper")
result = service.transcribe_file("audio.wav", service_type="whisper")
```

### 2. OpenAI Whisper API

- **ä¼˜ç‚¹**: å‡†ç¡®åº¦é«˜ï¼Œæ— éœ€æœ¬åœ°èµ„æº
- **ç¼ºç‚¹**: éœ€è¦ç½‘ç»œè¿æ¥ï¼Œæœ‰ API è°ƒç”¨è´¹ç”¨
- **é€‚ç”¨åœºæ™¯**: åœ¨çº¿ç¯å¢ƒï¼Œå¯¹å‡†ç¡®åº¦è¦æ±‚é«˜çš„åœºæ™¯

```python
service = VoiceToTextService(default_service="openai", api_key="your-api-key")
result = service.transcribe_file("audio.wav", service_type="openai")
```

## éŸ³é¢‘æ ¼å¼æ”¯æŒ

### æ”¯æŒçš„è¾“å…¥æ ¼å¼
- WAV
- MP3
- M4A
- FLAC
- OGG
- å…¶ä»–å¸¸è§éŸ³é¢‘æ ¼å¼

### éŸ³é¢‘è¦æ±‚
- **é‡‡æ ·ç‡**: å»ºè®® 16kHz æˆ–ä»¥ä¸Š
- **å£°é“**: å•å£°é“æˆ–ç«‹ä½“å£°
- **æ—¶é•¿**: å»ºè®®ä¸è¶…è¿‡ 25MB (OpenAI API é™åˆ¶)

## éŸ³é¢‘é¢„å¤„ç†

```python
from app.core.voice_to_text import AudioProcessor

# è½¬æ¢éŸ³é¢‘æ ¼å¼
AudioProcessor.convert_audio_format("input.mp3", "output.wav", "wav")

# åŠ è½½éŸ³é¢‘æ–‡ä»¶
audio_data, sample_rate = AudioProcessor.load_audio("audio.wav")
```

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

```bash
# OpenAI API Key
export OPENAI_API_KEY="your-api-key"

# é»˜è®¤æœåŠ¡ç±»å‹
export DEFAULT_VOICE_SERVICE="whisper"
```

### æœåŠ¡é…ç½®

```python
# åˆ›å»ºæœåŠ¡æ—¶æŒ‡å®šé…ç½®
config = {
    "model_size": "base",  # whisper æ¨¡å‹å¤§å°
    "language": "zh",      # é»˜è®¤è¯­è¨€
    "task": "transcribe"   # ä»»åŠ¡ç±»å‹
}

service = VoiceToTextService(
    default_service="whisper",
    config=config
)
```

## é”™è¯¯å¤„ç†

```python
try:
    result = service.transcribe_file("audio.wav")
    print(f"è½¬å½•æˆåŠŸ: {result}")
except Exception as e:
    print(f"è½¬å½•å¤±è´¥: {e}")
    # å¤„ç†é”™è¯¯
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹é€‰æ‹©

```python
# æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹å¤§å°
models = {
    "tiny": "æœ€å¿«ï¼Œå‡†ç¡®åº¦è¾ƒä½",
    "base": "å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®åº¦",
    "small": "è¾ƒå¥½å‡†ç¡®åº¦",
    "medium": "é«˜å‡†ç¡®åº¦",
    "large": "æœ€é«˜å‡†ç¡®åº¦ï¼Œæœ€æ…¢"
}
```

### 2. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å¤„ç†å¯ä»¥æé«˜æ•ˆç‡
audio_files = ["audio1.wav", "audio2.wav", "audio3.wav"]
results = service.batch_transcribe(audio_files)
```

### 3. ç¼“å­˜æœºåˆ¶

```python
# æœåŠ¡å®ä¾‹ä¼šç¼“å­˜æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½
service = VoiceToTextService()
# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šåŠ è½½æ¨¡å‹
result1 = service.transcribe_file("audio1.wav")
# ç¬¬äºŒæ¬¡è°ƒç”¨ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹
result2 = service.transcribe_file("audio2.wav")
```

## ç¤ºä¾‹ä»£ç 

å®Œæ•´çš„ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ `voice_example.py` æ–‡ä»¶ã€‚

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹ä¸‹è½½å¤±è´¥**
   ```bash
   # æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
   python -c "import whisper; whisper.load_model('base')"
   ```

2. **éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒ**
   ```python
   # è½¬æ¢éŸ³é¢‘æ ¼å¼
   AudioProcessor.convert_audio_format("input.mp3", "output.wav")
   ```

3. **API è°ƒç”¨å¤±è´¥**
   ```python
   # æ£€æŸ¥ API Key
   print(os.getenv("OPENAI_API_KEY"))
   ```

4. **å†…å­˜ä¸è¶³**
   ```python
   # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
   service = VoiceToTextService(config={"model_size": "tiny"})
   ```

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªåŠŸèƒ½ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚ 